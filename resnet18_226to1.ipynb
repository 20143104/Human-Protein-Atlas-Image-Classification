{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def imgRead(in_path):\n",
    "    r_img = Image.open(in_path+'_red.png')\n",
    "    g_img = Image.open(in_path+'_green.png')\n",
    "    b_img = Image.open(in_path+'_blue.png')\n",
    "    y_img = Image.open(in_path+'_yellow.png')\n",
    "    rgb_arr = np.stack([r_img, g_img, b_img, y_img], -1)\n",
    "    return Image.fromarray(rgb_arr)\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.imgnames = df['Id'].tolist()\n",
    "        self.labels = None if 'target_vec' not in df.columns else np.array(df.target_vec.values.tolist(), dtype = np.float32)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgnames)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = '/Users/csh/Desktop/kaggle/input/train/' + self.imgnames[idx]\n",
    "        image = imgRead(img_path)\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return self.transform(image), torch.from_numpy(label)\n",
    "        \n",
    "        return self.transform(image)\n",
    "class ProteinTestDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.imgnames = df['Id'].tolist()\n",
    "        self.labels = None if 'target_vec' not in df.columns else np.array(df.target_vec.values.tolist(), dtype = np.float32)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgnames)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = '/Users/csh/Desktop/kaggle/input/test/' + self.imgnames[idx]\n",
    "        image = imgRead(img_path)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return self.transform(image), torch.from_numpy(label)\n",
    "        \n",
    "        return self.transform(image), self.imgnames[idx]\n",
    "    \n",
    "def fetch_dataloader(types, data_dir):\n",
    "\n",
    "    assert set(types) <= set(\n",
    "        ['train', 'val', 'test']), \"data types have to be among {'train', 'val', 'test'}\"\n",
    "\n",
    "    train_transformer = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomRotation(20.0),\n",
    "        transforms.RandomHorizontalFlip(),  \n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.00505, 0.00331, 0.00344, 0.00519],\n",
    "                             std=[0.10038, 0.08131, 0.08284, 0.10179])\n",
    "])  \n",
    "\n",
    "    eval_transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.00505, 0.00331, 0.00344, 0.00519],\n",
    "                             std=[0.10038, 0.08131, 0.08284, 0.10179])\n",
    "])  \n",
    "\n",
    "    if 'test' in types:\n",
    "        test_image_dir = data_dir\n",
    "        test_df = pd.read_csv('/Users/csh/Desktop/kaggle/input/sample_submission.csv')\n",
    "\n",
    "    if 'train' in types:\n",
    "        train_image_dir = data_dir\n",
    "\n",
    "        train_df = pd.read_csv('/Users/csh/Desktop/kaggle/input/train.csv')\n",
    "\n",
    "        train_df['target_list'] = train_df['Target'].map(\n",
    "            lambda x: [int(a) for a in x.split(' ')])\n",
    "\n",
    "        # create a categorical vector\n",
    "        train_df['target_vec'] = train_df['target_list'].map(\n",
    "            lambda ck: [int(i in ck) for i in range(28)])\n",
    "\n",
    "        raw_train_df, valid_df = train_test_split(train_df,\n",
    "                            test_size=0.3,\n",
    "                          # hack to make stratification work\n",
    "                            stratify=train_df['target_list'].map(lambda x: np.random.choice(x) if 27 not in x else 27))\n",
    "\n",
    "        # keep labels with more than 500 objects\n",
    "        out_df_list = []\n",
    "        for k in range(28):\n",
    "            keep_rows = raw_train_df['target_list'].map(lambda x: k in x)\n",
    "            out_df_list += [raw_train_df[keep_rows].sample(1000,\n",
    "                                                           replace=True)]\n",
    "        train_df = pd.concat(out_df_list, ignore_index=True)\n",
    "\n",
    "    dataloaders = {}\n",
    "    for split in set(types):\n",
    "        # use the train_transformer if training data, else use eval_transformer without random flip\n",
    "        if split == 'train':\n",
    "            dl = DataLoader(ProteinDataset(train_df, train_transformer),\n",
    "                            batch_size=36,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4)\n",
    "            dataloaders[split] = dl\n",
    "        elif split == 'val':\n",
    "            dl = DataLoader(ProteinTestDataset(valid_df, eval_transformer),\n",
    "                            batch_size=4,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "            dataloaders[split] = dl\n",
    "        else:\n",
    "            dl = DataLoader(ProteinTestDataset(test_df, eval_transformer),\n",
    "                            batch_size=4,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "            dataloaders[split] = dl\n",
    "\n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataloaders = fetch_dataloader(['train', 'val'], '/Users/csh/Desktop/kaggle/input/train')\n",
    "    train_dl = dataloaders['train']\n",
    "    val_dl = dataloaders['val']\n",
    "    testloaders = fetch_dataloader(['test'], '/Users/csh/Desktop/kaggle/input/test')\n",
    "    test_dl = testloaders['test']\n",
    "    device = 'cuda'\n",
    "    net = torchvision.models.resnet18()\n",
    "    net.conv1 = nn.Conv2d(4, 64, kernel_size = (7, 7), stride= (2, 2), padding=(3, 3), bias=False)\n",
    "    net.fc = nn.Linear(512 , 28)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=5e-4)\n",
    "    for epoch in range(1):\n",
    "        with tqdm(total = len(train_dl)) as t:\n",
    "            running_loss = 0.0\n",
    "            for i, (train_batch, labels_batch) in enumerate(train_dl):\n",
    "                train_batch = train_batch.to(device), labels_batch = labels_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output_batch = net(train_batch)\n",
    "                loss = loss_fn(output_batch, labels_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                torch.save(net, '/Users/csh/Desktop/dna2.pt')\n",
    "                running_loss += loss.item()\n",
    "                if( i% 100 == 99):\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                     (epoch + 1, i+1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "     \n",
    "                t.update()\n",
    "    runnling_loss = 0.0\n",
    "    with tqdm(total = len(val_dl)) as t:\n",
    "        runnling_loss = 0.0\n",
    "        for i,(data_batch, labels_batch) in enumerate(val_dl):\n",
    "            output_batch = net(data_batch)\n",
    "            loss = loss_fn(output_batch, labels_batch)\n",
    "            running_loss += loss.item()\n",
    "    print(running_loss)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    torch.save(net, '/Users/csh/Desktop/dna2.pt')\n",
    "    out = []\n",
    "    for data_batch in tqdm(test_dl):\n",
    "        data_batch = data_batch.to(device)\n",
    "\n",
    "        output_batch = net(data_batch)\n",
    "\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        output_batch = (output_batch > -1.0).astype(np.int32)\n",
    "        for i in range(output_batch.shape[0]):\n",
    "            output_batch_str = ' '.join(str(v) for v in np.nonzero(ouput_batch[i])[0].tolist())\n",
    "\n",
    "            ouput.append(output_batch_str)\n",
    "\n",
    "    test_df = pd.read_csv('sample_submission.csv')\n",
    "    test_df.Predicted = out\n",
    "    test_df.to_csv('dna_submission.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
